providers:
  openai:
    model: gpt-4o
    api_key: "${OPENAI_API_KEY}"
    temperature: 0.7
    max_tokens: 4000
  
  anthropic:
    model: claude-3-opus
    api_key: "${ANTHROPIC_API_KEY}"
    temperature: 0.5
    max_tokens: 4000
  
  google:
    model: gemini-pro
    api_key: "${GOOGLE_API_KEY}"
    temperature: 0.6
  
  ollama:
    model: llama3.2
    base_url: "http://localhost:11434"
    temperature: 0.7

# Default provider to use
default_provider: openai

# Environment-specific settings
environments:
  development:
    default_provider: ollama
    temperature: 0.8
  
  production:
    default_provider: openai
    temperature: 0.3 